#+TITLE: NLP, Python
#+AUTHOR: Kholid Fuadi, SE., MSi
#+DATE: <2016-11-17 Thu>
#+STARTUP: indent

* I. Pendahuluan
Menurut wikipedia, Pemrosesan Bahasa Alami (PBA) atau NLP (Natural
Language Processing), adalah cabang ilmu komputer dan linguistik yang
mengkaji interaksi antara komputer dengan bahasa (alami)
manusia.[fn:1]

Secara sederhana, saya menterjemahkan NLP sebagai disiplin ilmu yang
berusaha untuk mempelajari bahasa manusia. Seperti diketahui bahasa
manusia sangat kompleks, namun bukan berarti tidak dapat dipahami oleh
komputer sama sekali. Dengan menggunakan analisis bentuk dan pola,
mesin yang sudah terlatih dapat mengetahui apa maksud yang terkandung
dalam sebuah teks.

Inilah yang menjadi tujuan dari NLP, membuat mesin memahami maksud
dari teks yang ditulis maupun diucapkan manusia. Anda bisa bayangkan
jika mesin dapat berinteraksi dengan manusia? Ya, kurang lebih seperti
si Jarvis dalam film Iron Man. Bahasa manusia yang diterima oleh
komputer perlu diproses dahulu supaya komputer dapat memahami maksud
dari bahasa manusia. Bahasa sendiri dapat dibagi menjadi 2, *bahasa
alami*, misal bahasa indonesia, jawa, inggris dan *bahasa buatan*,
misal bahasa pemrograman komputer, bahasa pemodelan.

Sebelum sampai ke materi yang sulit, saya ingin mulai belajar NLP dari
hal-hal yang sederhana dahulu.

** I.1 Aplikasi NLP[fn:2]
- Mesin penjawab pertanyaan otomatis
- Program pengategorian dokumen otomatis
- Text mining
- Mesin translasi
- Program pembelajaran bahasa
- Spelling correction
- Plagiarism detection
- Speech recognition
- Text to speech

** I.2 Kendala NLP
- Bahasa = kata + aturan + pengecualian
- Bahasa alami mengandung ambiguitas
- Bahasa manusia tidak hanya satu
- Bahasa manusia terus berubah, misalnya fenomena kemunculan bahasa
  alay.

** I.3 Istilah-istilah dalam NLP
Sebagai seorang awam dalam dunia linguistik, bagi saya penting untuk
mengetahui istilah-istilah yang sering digunakan dalam NLP.
*** /tokenizing/
Proses memecah kata atau kalimat, kalau kata berdasar spasi, kalau
kalimat berdasar tanda baca titik. Teknik yang digunakan bisa
menggunakan ~regex~ atau menggunakan fungsi dari pustaka
~nltk~. Berikut ini contoh kode:

#+BEGIN_SRC python
  from nltk.tokenize import sent_tokenize, word_tokenize

  text = "Selamat pagi Pak Ahok, bagaimana kabarnya? Semoga sehat selalu."

  print sent_tokenize(text)
  print word_tokenize(text)
#+END_SRC

Hasilnya:

#+BEGIN_SRC python
  ['Selamat pagi Mr. Ahok, bagaimana kabarnya?', 'Semoga sehat selalu.']
  ['Selamat', 'pagi', 'Mr.', 'Ahok', ',', 'bagaimana', 'kabarnya', '?',
  'Semoga', 'sehat', 'selalu', '.']
#+END_SRC

Beruntung, karena karakter huruf Bahasa Indonesia sama dengan Bahasa
Inggris, fungsi ini dapat kita gunakan untuk Bahasa Indonesia
juga. Terlihat bahwa pustaka ~nltk~ sudah menyediakan fungsi yang
/reliable/ untuk memecah kalimat atau kata dengan benar.

*** /corpora/
Naskah teks, misal naskah pidato presiden, jurnal ekonomi.
*** /lexicon/
Kata dan artinya (mirip kamus). Contoh, kata 'tahu' bisa bermakna
makanan atau bisa juga paham. Kalau dalam bahasa Inggris, kata _bull_
bagi investor berbeda makna dengan _bull_ bagi pembicara biasa.
*** /stop words/
Kata penghubung kalau dalam bahasa Indonesia. Kalau dalam bahasa
Inggris, pustaka ~nltk~ sudah menyediakan daftar /stopwords/ yang
tinggal diunduh, lain halnya dengan Bahasa Indonesia. Kita harus
menambahkan secara manual, beruntung ada beberapa tautan di Internet
yang menyediakan, dan sudah saya unduh di direktori
~dataset~[fn:4]. Mari kita coba terapkan untuk mengidentifikasi kata
penghubung dalam Bahasa Indonesia:

#+BEGIN_SRC python
import os


stopword_file = os.path.join('.', 'dataset/stopword_list_indo.txt')

with open(stopword_file, 'r') as f:
    stopwords = f.read()

stopwords = [i for i in stopwords.split('\n')]
return stopwords[:5]
#+END_SRC

#+RESULTS:
| ada | adalah | adanya | adapun | agak | 

Sekarang mari gunakan untuk mengidentifikasi kata penghubung dalam
kalimat berikut:

#+BEGIN_SRC python
import os
from nltk.tokenize import word_tokenize


# reading stopword_list_indo.txt
stopword_file = os.path.abspath(os.path.join('.',
                                             'dataset/stopword_list_indo.txt'))
with open(stopword_file, 'r') as f:
    stopwords = f.read()

stopwords = [i for i in stopwords.split('\n')]

teks = "Semenjak dihadang warga ketika kampanye, Ahok sekarang sering \
melakukan kegiatan kampanye di poskonya."

words = word_tokenize(teks)

filtered_sentence = [w for w in words if not w in stopwords]
print filtered_sentence
#+END_SRC

Hasilnya:

#+BEGIN_SRC python
['Semenjak', 'dihadang', 'warga', 'kampanye', ',', 'Ahok', 'kegiatan',
'kampanye', 'poskonya', '.']
#+END_SRC

Terlihat bahwa kata ~sekarang~, ~ketika~, ~sering~, ~melakukan~ dan
~di~ dianggap sebagai kata penghubung sehingga dihilangkan dari
~teks~. Inilah salah satu contoh proses /tokenization/ dan
membersihkan teks dari kata penghubung.

*** /stemming/
Mengubah kata ke bentuk aslinya, tanpa memperhatikan konteks. Beberapa
jenis stemming Bahasa Indonesia yang ada mulai dari Nazief adriani,
Arifin-setiono, Tala, hingga Sembok. Stemming yang populer digunakan
yaitu *Nazief Adriani (NA)* karena akurasi yang dihasilkan dapat
dikatakan cukup tinggi hingga mencapai 94%.

Referensi menarik di tema ini:
- [[https://liyantanto.wordpress.com/2011/06/28/stemming-bahasa-indonesia-dengan-algoritma-nazief-dan-andriani/][Stemming bahasa indonesia dengan algoritma nazief dan andriani]]
- [[http://sastrawi.github.io/][sastrawi - library untuk stemming]]
- [[https://yudiagusta.files.wordpress.com/2009/11/196-201-knsi09-036-perbandingan-algoritma-stemming-porter-dengan-algoritma-nazief-adriani-untuk-stemming-dokumen-teks-bahasa-indonesia.pdf][Perbandingan algoritma stemming Porter dengan algoritma Nazief
  Adriani untuk stemming dokumen teks bahasa Indonesia]]
*** /lemmatization/
Mengubah kata ke bentuk asalnya, dengan memperhatikan konteks.
*** /treebank/
*** /pos tag/
* II. Rumusan Masalah
** Batasan Masalah
Batasan rumusan masalah disini adalah dalam konteks bahasa Indonesia,
karena memang belum banyak penelitian maupun /dataset/ dalam bahasa
Indonesia
** Tujuan
Tujuan dari /paper/ ini adalah membuat aplikasi analisis sentimen
sederhana menggunakan bahasa pemrograman Python.
* III. Metode
** III.1 Sumber Data (Domain):
- Koran
- Teks legal
- Novel
- E-mail
- SMS
- Customer Review
- Blog post
- Twitter
- Kaskus
- Facebook
- etc.
* IV. Analisis
** IV.1 Analisis Sentimen
Apakah teks bermakna *positif*, *negatif* atau *netral*? Sumber teks
bisa dari kalimat, tweet, pesan SMS, review konsumen, dokumen, dan
seterusnya.
Contoh penerapan di dunia nyata:
- Bagaimana sentimen terhadap sebuah aspek dari produk?
- Bagaimana sentimen terhadap politisi, kebijakan pemerintah,
  perusahaan atau produk?
*** Message level sentiment
- Positive
- Negative
- Neutral
- Indeterminate
- Both positive and negative
** IV.2 Analisis Emosi[fn:3]
Apa emosi yang terkandung dalam sebuah teks? *Senang*, *susah*,
*ketakutan*, *marah*?
* V. Kesimpulan
* Daftar Pustaka
- [ ] Pusat Bahasa UI, http://bahasa.cs.ui.ac.id/about.php
- [ ] Natural Language Processing (almost) from Scratch,
  https://arxiv.org/pdf/1103.0398v1.pdf
- [ ] Kumpulan video PBA di youtube,
  https://www.youtube.com/results?search_query=pemrosesan+bahasa+alami
- [ ] Sentiment Analysis of Social Media Texts Part 1,
  https://www.youtube.com/watch?v=zv16Xyph7Ss
* Footnotes

[fn:4] [[http://hikaruyuuki.lecture.ub.ac.id/kamus-kata-dasar-dan-stopword-list-bahasa-indonesia/][Kamus kata dasar dan stopword list bahasa indonesia]]

[fn:1] [[https://id.wikipedia.org/wiki/Pemrosesan_bahasa_alami][Pemrosesan Bahasa Alami {wikipedia}]]

[fn:2] https://youtu.be/nSzrOl_vnn4?t=61

[fn:3] https://youtu.be/zv16Xyph7Ss?t=176
